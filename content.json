{"pages":[{"title":"关于我","text":"还没想好如何描述","link":"/about/index.html"}],"posts":[{"title":"GraalVM浅析","text":"1. 架构篇 GraalVM 主要包含两个功能及其他附属功能： 多语言的编译器和运行时环境 对基于 JVM 的语言的原生编译 1.1 多语言的编译器和运行时环境对于编程语言的开发人员而言，只需要完成对一门编程语言的解析工作，它的虚拟机实现则可以交给 GraalVM。 GraalVM 分为三部分： 本身就基于 jvm 的语言，如 Java、Scala、kotlin 等等 动态语言，如 Python，JS，Ruby 等 其他静态语言，如 golang，R 语言 等 GraalVM 对这三种语言的虚拟机实现，原理如下： 对字节码文件 “翻译“ 成机器码 将动态语言解析成 “AST”，编译器将 “AST” 转换成机器码 c/c++ 代码 -&gt; llvm 字节码 -&gt; “AST” -&gt; 机器码 1.2 原生编译原生编译依赖于 AOT 技术，AOT 技术就是在编译的时候，直接将源代码编译成机器码。 jit 编译技术是用 javac 将源码编译成字节码，执行的时候，再由 jvm 的 jit 编译器将字节码翻译成机器码。 GraalVM 有三种运行模式： jvm 模式 native image 模式 Java on truffle 模式 其中，native image 模式就是使用的 AOT 技术。 2. 安装方式GraalVM 本身就包含了 jdk (社区版基于 openjdk，商业版基于Oracle jdk)，在它的 /bin 目录中，包含了 jdk 的各种命令，如 java、javac等。 3. 主要组件GraalVM 安装后，/bin 目录中除了 jdk 本身自带的 Java 相关命令，还默认带了三个工具： js：js 执行器 lli：LLVM 字节码执行器 gu：安装其他语言和工具 比如，想在 GraalVM 中使用 nodejs，那么只需要执行：gu install nodejs，执行成功之后，GraalVM 的 bin 目录中将会包含 nodejs 的命令行工具，在终端中也可以直接使用 node -v。","link":"/2022/05/02/GraalVM%E6%B5%85%E6%9E%90/"},{"title":"Nginx学习总结","text":"1 概述主要对nginx进行介绍 2 基础知识2.1 应用场景 静态资源服务 反向代理 缓存 负载均衡 API服务 OpenResty 2.2 组成 nginx 二进制组成文件 nginx配置文件 access.log：记录每一条http请求信息 error.log：记录错误信息 2.3 版本使用nginx：开源版 OpenResty：开源版 2.4 编译安装nginx步骤： 下载nginx 执行./configure make make install 源碼目錄解釋： nginx 语法高亮加载 123# 进入nginx解压目录cp -r contrib/vim/* ~/.vim/ ./configure参数： 可以指定安装目录 可以指定加载和不加载模块 可以指定编译优化参数 如何给已安装的nginx重新安装模块 2.5 配置文件conf文件中，由http包含所有，http中可以包含http、upstream、server、location四个部分 2.6 静态资源搭建 alias命令使用 开启gzip autoindex模块 限速：$limit_rate log_format格式化日志 1234567location / { alias /opt/upload/file/; autoindex on; autoindex_localtime on; charset utf-8;} 2.7 反向代理2.8 使用goaccess可视化1goaccess access.log -o /opt/html/report.html --real-time-html --time-format='%H:%M:%S' --date-format='%d/%b/%Y' --log-format=COMBINED 2.9 CORS处理1234567891011121314151617181920212223242526272829303132333435363738394041424344http { map $http_origin $allow_origin { default &quot;&quot;; &quot;~^(https?://localhost(:[0-9]+)?)&quot; $1; &quot;~^(https?://127.0.0.1(:[0-9]+)?)&quot; $1; &quot;~^(https?://192.168.254.[\\d]+(:[0-9]+)?)&quot; $1; &quot;~^(https?://202.104.150.229(:[0-9]+)?)&quot; $1; &quot;~^(https?://103.39.235.17(:[0-9]+)?)&quot; $1; &quot;~^(https?://([\\w]+.)?([\\w]+.)?[\\w]+.rainbowecho.top)&quot; $1; #&quot;~^(https?://qzs.stcn.com)&quot; $1; } server { location / { # proxy_pass http://appapi.stcn.com; # 压测临时调整 proxy_pass proxy_pass http://192.168.254.205:8582; # proxy_pass http://192.168.254.77:8582; # nginx的代理后端是另一个LSB proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; # 是否允许请求带有验证信息 add_header Access-Control-Allow-Credentials true; # 允许跨域访问的域名,可以是一个域的列表，空格隔开，也可以是通配符*（不建议） add_header Access-Control-Allow-Origin $allow_origin; # 允许使用的请求方法，以逗号隔开，可以用 * add_header Access-Control-Allow-Methods 'POST,GET,OPTIONS,PUT,DELETE'; # 预检命令的缓存，如果不缓存每次会发送两次请求，单位为秒。 # 第一次是浏览器使用OPTIONS方法发起一个预检请求，第二次才是真正的异步请求 add_header Access-Control-Max-Age 3600; # 允许脚本访问的返回头 #add_header Access-Control-Allow-Headers 'Authorization,Content-Type,Accept,Origin,User-Agent,DNT,Cache-Control,X-Mx-ReqToken,X-Requested-With'; add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization,credential'; # OPTIONS类的请求，是跨域先验请求 if ($request_method = 'OPTIONS') { return 204; # http状态码 204 （无内容） 服务器成功处理了请求，但没有返回任何内容。可以返回 200 } } }} CORS测试，在一台配置了带有https的nginx的主机上编写一个HTML，在HTML中发送ajax请求，如： 123456789101112131415161718192021222324252627282930&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;CORS跨域&lt;/title&gt; &lt;script src=&quot;https://libs.baidu.com/jquery/2.0.0/jquery.min.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div style=&quot;text-align:center;margin-top: 100px;font-size: 60px;color: brown;cursor: pointer;&quot;&gt; &lt;button onclick=&quot;sendAjaxReq()&quot;&gt;发送Ajax请求&lt;/button&gt;&lt;/div&gt;&lt;script type=&quot;text/javascript&quot;&gt; function sendAjaxReq() { $.ajax({ headers: { Authorization: &quot;Bearer eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJyZWd1c2VyNjBAcXNjbiIsImlhdCI6MTYxMDQyMTcxMCwiZXhwIjoxNjE1NjA1NzEwLCJhdXRoVHlwZSI6MH0.Q57Wc7n0gSMuwYqSLe0llN1gssspLKu00pYii9HQGMg&quot; }, type: &quot;get&quot;, // contentType: &quot;application/json&quot;, url: &quot;https://qzsapi.stcn.com/comment/api/comments/article/2317345?page=0&amp;size=9&quot;, success: function (message) { console.log(&quot;成功！&quot; + message); }, error: function (a, b, c) { console.log(&quot;失败！&quot; + a.statusText); } }); }&lt;/script&gt;","link":"/2022/05/02/Nginx%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"},{"title":"Keycloak token 有效期配置","text":"关键配置如下图： 更改 realm 配置：Access token lifespan：token 有效时长SSO Session Idle：refresh token 有效时长","link":"/2022/05/02/Keycloak-%E6%9C%89%E6%95%88%E6%9C%9F%E9%85%8D%E7%BD%AE/"},{"title":"Jackson使用指北","text":"1. 概述Jackson是目前在web开发中使用最多，速度最快的一种json序列化和反序列化框架。本文主要结合Jackson在项目中的实际使用进行介绍。 2. 字段忽略2.1 json转POJO时，忽略某些字段只需要在实体类上加上@JsonIgnoreProperties(ignoreUnknown = true)注解就可以。 2.2 POJO转json时，忽略某些字段@JsonIgnore注解用来忽略某些字段，可以用在Field或者Getter方法上，用在Setter方法时，和Filed效果一样 3. json转换为POJO3.1 json字符串直接转POJOobjectMapper.readValue(json, xxx.class) 适用于json字符串与POJO直接一一对应。 3.2 json字符串转JsonNode12345JsonNode rootNode = objectMapper.readTree(json);// 获取其中某个字段的数据JsonNode dataNode = rootNode.findValue(&quot;xxx&quot;);// 将数据反序列化为POJOobjectMapper.treeToValue(dataNode, xxx.class); 适用于Json字符串的某一部分与JsonNode对应。先获取json响应中的某一部分数据，再将该数据转换为POJO 3.3 json转泛型类1AiReply&lt;SensitiveImageReply&gt; reply = objectMapper.readValue(json, new TypeReference&lt;AiReply&lt;SensitiveImageReply&gt;&gt;() {}); 3.4 json转数组和列表12345678910List&lt;Person&gt; personList = new ArrayList&lt;Person&gt;() { { add(new Person(&quot;yangjian&quot;, 22)); add(new Person(&quot;zhanghaoman&quot;, 22)); }};String personJson = this.objectMapper.writeValueAsString(personList);List&lt;Person&gt; persons = this.objectMapper.readValue(personJson, List.class);System.out.println(&quot;persons = &quot; + persons); 3.5 类拷贝1234567891011121314 // 拷贝成map Person person = new Person(&quot;yangjian&quot;, 23); String json = this.objectMapper.writeValueAsString(person); Map&lt;String, Object&gt; map = this.objectMapper.convertValue(person, Map.class); // 链表到数组拷贝 List&lt;String&gt; list = new ArrayList&lt;String&gt;() { { add(&quot;one&quot;); add(&quot;two&quot;); } }; String[] strings = this.objectMapper.convertValue(list, String[].class); System.out.println(&quot;this.objectMapper.writeValueAsString(strings) = &quot; + this.objectMapper.writeValueAsString(strings)); 4. POJO转换为json4.1 设置视图@JsonView(xxx.class)注解可以实现视图显示，序列化的json只会包含有相同视图修饰的字段。并且，视图可以继承。此注解，POJO类上和controller的方法上都需要加。 4.2 自定义某个字段的序列化/反序列化方式使用SpringMVC的@RestController时，我们都知道如果返回的是一个POJO，那么SpringMVC将会自动进行POJO的序列化。但有些时候我们往往需要对该POJO某个字段的序列化和反序列化的方式进行一些修改，以满足我们的业务需求。这时候就可以用到@JsonSerialize和@JsonDeserialize 用法： POJO 12345678910111213141516171819202122232425262728293031323334/** * Tencent AI 身份证OCR响应数据的POJO * * @author rainbow * @since 2020/3/20 10:56 */@Data@EqualsAndHashCode(callSuper = false)@Accessors(chain = true)@JsonIgnoreProperties(ignoreUnknown = true)@NoArgsConstructorpublic class IdCardOcrData { private String name; private String sex; private String nation; @JsonDeserialize(using = IdCardLocalDateDeserializer.class) @JsonSerialize(using = IdCardLocalDateSerializer.class) private LocalDate birth; private String address; private String id; private String authority; /** * 有效时限 */ private String valid_date;} IdCardLocalDateSerializer类 123456789101112/** * @author rainbow * @since 2020/3/20 16:25 */public class IdCardLocalDateSerializer extends JsonSerializer&lt;LocalDate&gt; { @Override public void serialize(LocalDate value, JsonGenerator gen, SerializerProvider serializers) throws IOException { DateTimeFormatter timeFormatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;); gen.writeString(timeFormatter.format(value)); }} IdCardLocalDateDeserializer类 12345678910111213141516/** * @author rainbow * @since 2020/3/20 13:05 */public class IdCardLocalDateDeserializer extends JsonDeserializer&lt;LocalDate&gt; { @Override public LocalDate deserialize(JsonParser p, DeserializationContext ctxt) throws IOException { String dateString = p.getText(); if (StringUtils.isNotBlank(dateString)) { String[] split = dateString.split(&quot;/&quot;); return LocalDate.of(Integer.parseInt(split[0]), Integer.parseInt(split[1]), Integer.parseInt(split[2])); } return null; }} 以上的例子可以将 “2020/2/1” 格式的字符串反序列化为LocalDate类，并将其序列化为 “2020-02-02” 格式的json数据。 4.3 自定义字段序列化方式@JsonFormat此注解用于属性或者方法上（最好是属性上），可以方便的把Date类型直接转化为我们想要的模式，比如@JsonFormat(pattern = &quot;yyyy-MM-dd HH-mm-ss&quot;， timezone = &quot;GMT+8&quot;) 5. 自定义objectMapper使用SpringBoot自动装配的ObjectMapper在某些情况不太适用，比如它会将值为null的字段也进行序列化返回。因此，我们对ObjectMapper进行设置，达到自己想要的效果。 具体配置类为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Configurationpublic class JacksonConfig { private static final String FORMAT = &quot;yyyy-MM-dd HH:mm:ss&quot;; @Bean public Jackson2ObjectMapperBuilderCustomizer customizer() { return builder -&gt; { builder.locale(Locale.CHINA); builder.timeZone(TimeZone.getTimeZone(ZoneId.systemDefault())); builder.simpleDateFormat(FORMAT); JavaTimeModule javaTimeModule = new JavaTimeModule(); javaTimeModule.addSerializer(LocalDateTime.class, new LocalDateTimeSerializer( DateTimeFormatter.ofPattern(FORMAT))); javaTimeModule.addSerializer(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;))); javaTimeModule.addSerializer(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(&quot;HH:mm:ss&quot;))); javaTimeModule.addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;))); javaTimeModule.addDeserializer(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;))); javaTimeModule.addDeserializer(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(&quot;HH:mm:ss&quot;))); builder.modules(javaTimeModule); }; } @Bean @Primary public ObjectMapper jacksonObjectMapper(Jackson2ObjectMapperBuilder builder) { ObjectMapper objectMapper = builder.createXmlMapper(false).build(); // 通过该方法对mapper对象进行设置，所有序列化的对象都将按改规则进行系列化 // Include.Include.ALWAYS 默认 // Include.NON_DEFAULT 属性为默认值不序列化 // Include.NON_EMPTY 属性为 空（&quot;&quot;） 或者为 NULL 都不序列化，则返回的json是没有这个字段的 // Include.NON_NULL 属性为NULL 不序列化 objectMapper.setSerializationInclusion(JsonInclude.Include.NON_NULL); // 允许出现特殊字符和转义符 objectMapper.configure(JsonParser.Feature.ALLOW_UNQUOTED_CONTROL_CHARS, true); // 允许出现单引号 objectMapper.configure(JsonParser.Feature.ALLOW_SINGLE_QUOTES, true); //objectMapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS); //objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); /** * 将Long,BigInteger序列化的时候,转化为String */ // SimpleModule simpleModule = new SimpleModule(); // // simpleModule.addSerializer(Long.class, ToStringSerializer.instance); // simpleModule.addSerializer(Long.TYPE, ToStringSerializer.instance); // simpleModule.addSerializer(BigInteger.class, ToStringSerializer.instance); // // objectMapper.registerModule(simpleModule); return objectMapper; }} 该配置类能对类的LocalDateTime等新时间类进行序列化，也能对序列化和反序列化解析方式进行设置。","link":"/2022/05/02/Jackson%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8C%97/"},{"title":"RabbitMQ总结","text":"1. 原理及基本概念原理如图： 其中涉及到的基本分别为： broker：消息队列服务器的实体 exchange：消息交换机。publisher将消息交给exchange，exchange负责将消息发送到queue中 publisher：消息生产者 consumer：消息消费者 channel：消息传递的通道 routing key：路由关键字。exchange根据routing key投递消息与之绑定的queue binding：将queue与exchange按照routing key的规则绑定起来 virtual host：用作不同用户的权限分离 2. 交换机类型最新版本的RabbitMQ有四种交换机类型，分别是Direct exchange、Fanout exchange、Topic exchange、Headers exchange。 Direct Exchange：要求该消息与一个特定的路由键完全匹配。 Fanout Exchange：发送到交换机的消息都会被转发到与该交换机绑定的所有队列上 Topic Exchange：将路由键和某模式进行匹配。 Headers exchange：根据发送的消息内容中的headers属性进行匹配。在绑定Queue与Exchange时指定一组键值对；当消息发送到RabbitMQ时会取到该消息的headers与Exchange绑定时指定的键值对进行匹配；如果完全匹配则消息会路由到该队列，否则不会路由到该队列 3. 集成SpringBoot使用Spring提供的启动器：spring-boot-starter-amqp，就可以很方便的开始使用启动器。 进行测试的时候，最好是将消费者与生产者分为两个不同的项目。使用延迟队列时，消费者最好使用字节数组去接收数据 4. 延迟队列4.1 流程图 4.2 原理RabbitMq实现延迟队列本身有两种方式： 使用延迟插件 使用TTL消息和死信队列 本文阐述的是第二种。原理很简单，TTL消息如果在规定的时间内没有被消费，RabbitMq就会认为是死信，转发到死信交换机。所以我们只需要向延时交换机发送一个我们想延时处理的消息，不去监听延时队列，而是监听死信队列进行消费，就会达到一个延时的效果。 死信的判定标准： 消息的TTL过期且未消费 消费者对broker应答Nack，并且消息禁止重回队列 Queue队列长度已达上限。 4.3 操作步骤本文使用SpringBoot结合RabbitMq的方式进行操作，引入的依赖版本是：2.1.5 - spring - boot - starter - amqp。 步骤如下： 引入amqp依赖 配置文件中配置RabbitMq服务器信息 使用Java代码进行队列、交换机等配置 声明死信队列、死信交换机，绑定死信队列和死信交换机 声明延时交换机，声明延时队列时添加x-dead-letter-exchange、x-dead-letter-routing-key两个参数，绑定延时队列和延时交换机 声明消费者，监听死信队列 第三步代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package top.rainbowecho.rabbit.consumer.config;import com.google.common.collect.ImmutableMap;import org.springframework.amqp.core.Binding;import org.springframework.amqp.core.BindingBuilder;import org.springframework.amqp.core.Queue;import org.springframework.amqp.core.TopicExchange;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @author rainbow * @since 2020/3/8 18:23 */@Configurationpublic class RabbitMqConfiguration { public static final String DELAY_ROUTING_KEY = &quot;delay.routing&quot;; public static final String DELAY_EXCHANGE = &quot;delay_exchange_10&quot;; public static final String DELAY_QUEUE = &quot;delay_queue&quot;; public static final String DLX_EXCHANGE = &quot;dlx_exchange&quot;; public static final String DLX_QUEUE = &quot;dlx_queue&quot;; public static final String DLX_ROUTING = &quot;#&quot;; @Bean public Binding dlxBinding() { return BindingBuilder.bind(dlxQueue()).to(dlxExchange()).with(DLX_ROUTING); } @Bean public TopicExchange dlxExchange() { return new TopicExchange(DLX_EXCHANGE); } @Bean public Queue dlxQueue() { return new Queue(DLX_QUEUE); } /** * 声明延迟队列的时候将该队列绑定到死信交换机 * * @return 延迟队列 */ @Bean public Queue businessQueue() { ImmutableMap&lt;String, Object&gt; arguments = ImmutableMap.of(&quot;x-dead-letter-exchange&quot;, DLX_EXCHANGE, &quot;x-dead-letter-routing-key&quot;, DLX_ROUTING); return new Queue(DELAY_QUEUE, true, false, false, arguments); } @Bean public TopicExchange businessExchange() { return new TopicExchange(DELAY_EXCHANGE); } @Bean public Binding businessBinding() { return BindingBuilder.bind(businessQueue()).to(businessExchange()).with(DELAY_ROUTING_KEY); }} 第四步代码： 12345678910111213141516171819202122232425262728package top.rainbowecho.rabbit.consumer.listener;import com.rabbitmq.client.Channel;import lombok.extern.slf4j.Slf4j;import org.springframework.amqp.rabbit.annotation.RabbitListener;import org.springframework.amqp.support.AmqpHeaders;import org.springframework.messaging.handler.annotation.Header;import org.springframework.stereotype.Component;import top.rainbowecho.rabbit.consumer.config.RabbitMqConfiguration;import java.io.IOException;/** * @author rainbow * @since 2020/3/8 18:44 */@Component@Slf4jpublic class BusinessMqListener { @RabbitListener(queues = RabbitMqConfiguration.DLX_QUEUE) public String businessMqListen(String mess, Channel channel, @Header(AmqpHeaders.DELIVERY_TAG) long deliveryTag) throws IOException { log.info(&quot;生产者发送的消息内容：&quot; + mess); channel.basicAck(deliveryTag, false); return &quot;消费者已经收到deliverTag为 &quot; + deliveryTag + &quot; 的消息&quot;; }} 4.4 生产者发送测试消息123456789101112131415161718192021222324252627282930package top.rainbowecho.rabbit;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.amqp.core.MessageDeliveryMode;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;import top.rainbowecho.rabbit.consumer.config.RabbitMqConfiguration;@RunWith(SpringRunner.class)@SpringBootTestpublic class RabbitApplicationTests { @Autowired private RabbitTemplate rabbitTemplate; @Test public void sendMessToMq() throws InterruptedException { String mess = &quot;hello, 死信队列&quot;; rabbitTemplate.convertAndSend(RabbitMqConfiguration.DELAY_EXCHANGE, RabbitMqConfiguration.DELAY_ROUTING_KEY, mess, message -&gt; { message.getMessageProperties().setDeliveryMode(MessageDeliveryMode.PERSISTENT); message.getMessageProperties().setExpiration(&quot;10000&quot;); return message; }); // 避免因为生产者发送成功而停掉整个程序 Thread.sleep(20000); }}","link":"/2022/05/02/RabbitMQ%E6%80%BB%E7%BB%93/"},{"title":"es 指北","text":"1 概述基于 ES 7.14.1，主要讲述 es 如何搭建、集成以及一些常见的坑 2 es 搭建https://gitee.com/zhengqingya/docker-compose.git 3 es 集成使用 spring data elasticsearch Spring data elasticsearch 与 springboot、elasticsearch 版本对照表 es 的版本可以稍高，比如笔者用的是 springboot 2.4.x，但是 es 用的是 7.14.1 集成方式： 引入 maven 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt;&lt;/dependency&gt; 定义 repository 12public interface EsStatusRepository extends ElasticsearchRepository&lt;EsStatus, String&gt; {} 定义了 repository 之后，就可以直接通过 autowire 注解引入，然后进行 es 数据操作 4 常见坑4.1 时间存储与显示使用 field 注解，格式化模式定义为：uuuu-MM-dd HH:mm:ss 这样，存储到 es 中的日期就是 年月日 时分秒 格式 但是，这个时候在 kibana 上显示出来，日期可能跟插入的日期不对，这是因为 kibana 设置了显示时的时区。更改方式如下： 设置为 UTC 4.2 开发工具点击开发工具，能够直接调用 es api 完成操作","link":"/2022/06/24/es-%E6%8C%87%E5%8C%97/"},{"title":"spring data 使用多种数据源的 repository","text":"1 前言笔者在使用 spring官方提供的关于 neo4j 和 elasticsearch 的 spring data 工程时发现，这个工程对应 repository 无法同时扫描 后面在官方文档中，还是找到了解决方法，解决方法如下： 2 具体方案12345@Configuration@EnableNeo4jRepositories(&quot;com.example.neo4j.repository&quot;)@EnableElasticsearchRepositories(&quot;com.example.es.repository&quot;)public class RepositoryConfig {} 添加这样一个配置，指定 repository 对应的包名即可","link":"/2022/06/24/spring-data-%E4%BD%BF%E7%94%A8%E5%A4%9A%E7%A7%8D%E6%95%B0%E6%8D%AE%E6%BA%90%E7%9A%84-repository/"},{"title":"nginx 配置 wss","text":"1 概述实际上，wss 配置也是基于 https。因此，在配置 wss 之前，应该先配置好 https。 以 conf.d 下 nginx 配置文件举例，https 参考配置如下： 123456789101112131415161718192021222324252627282930313233upstream 服务名(英文) { ip_hash; # 内网地址 server 内网机器ip:9998 weight=1 fail_timeout=10s max_fails=1;}server { listen 80; server_name 域名; return 301 https://$server_name$request_uri;}server { listen 443 ssl; server_name 域名; # ssl证书地址 ssl_certificate pem文件; ssl_certificate_key key文件; # ssl验证相关配置 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { add_header X-Upstream $upstream_addr; proxy_pass http://服务名(英文); }} 以上配置即可将一个后端项目通过 nginx 进行反向代理、负载均衡以及配置 https。 2 wss 实现在配置好 https 之后，假如你的后端项目本身已经添加了 websocket 端点，那么只需要再加三行配置就可以再让 nginx 配置好 wss。示例配置如下： 12345678910111213141516171819202122232425262728293031323334upstream 服务名(英文) { ip_hash; # 内网地址 server 内网机器ip:9998 weight=1 fail_timeout=10s max_fails=1;}server { listen 80; server_name 域名; return 301 https://$server_name$request_uri;}server { listen 443 ssl; server_name 域名; # ssl证书地址 ssl_certificate pem文件; ssl_certificate_key key文件; # ssl验证相关配置 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { add_header X-Upstream $upstream_addr; proxy_pass http://服务名(英文); proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; }} 注意 location 代码段新加的三行配置。","link":"/2022/06/24/nginx-%E9%85%8D%E7%BD%AE-wss/"},{"title":"Nginx反向代理","text":"1. 概述Nginx 支持两种反向代理，四层反向代理和七层反向代理。这个层数指的是网络协议的层级，以 OSI 七层模型为准。 七层代理指的是代理具体的协议，如 http 和 https 协议。 四层代理是直接针对 TCP、UDP 等 下面来看一下具体的实现方式 2. 七层反向代理七层反向代理的通用场景是反向代理 web 服务，配置 https 证书，使得这个 web 服务可以通过 https 方式访问。 举个例子，比如在机器 A 运行了一个 rabbitmq 服务，这个服务监听的是机器 A 的 15672 端口。但如果我们想通过 https 访问的话，就需要在机器 B 上运行一个 Nginx 服务，配置七层反向代理和 https 证书文件。 配置方式为： 12345678910111213141516171819202122232425262728293031upstream mq { ip_hash; # 内网地址 server 127.0.0.1:15672 weight=1 fail_timeout=10s max_fails=1;}server { listen 80; server_name mq.rainbowecho.cn; return 301 https://$server_name$request_uri;}server { listen 443 ssl; server_name mq.rainbowecho.cn; # ssl证书地址 ssl_certificate /etc/nginx/ssl/mq.rainbowecho.cn/mq.rainbowecho.cn.pem; ssl_certificate_key /etc/nginx/ssl/mq.rainbowecho.cn/mq.rainbowecho.cn.key; # ssl验证相关配置 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / { add_header X-Upstream $upstream_addr; proxy_pass http://mq; }} 3. 四层代理七层代理的局限性在于它只能代理 web 服务并手动配置 https。但如果我们需要代理 MySQL 或者为已经配置了 https 的服务配置代理，这个时候就需要四层反向代理。 由于四层反向代理是直接转发 TCP/UDP 连接，因此适配多种协议。 以代理 drone 为例，由于 drone 容器本身就配置了 https 访问，因此必须使用四层代理。配置如下，通过使用 Nginx 的 stream 模块，将匹配到的域名转发到对应的 upstream 上，upstream 中配置的就是代理的服务。 12345678910111213141516171819stream { map_hash_bucket_size 64; map $ssl_preread_server_name $backend_pool { drone.rainbowecho.cn drone_server; } upstream drone_server{ server 172.20.126.143:444; } server { listen 443; ssl_preread on; proxy_pass $backend_pool; proxy_connect_timeout 15s; proxy_timeout 15s; proxy_next_upstream_timeout 15s; }} 4. 总结对于同一个 Nginx，四层代理和七层代理监听的端口不能相同。也就是说，如果你想在同一个 nginx 上使用四层代理和七层代理去进行 https 代理的话，那么将会端口冲突。","link":"/2022/05/02/Nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"},{"title":"spring 自定义注入 bean","text":"1 概述有时候，需要想通过编程方式自定义一些 bean，因为我们需要根据业务逻辑，将这些 bean 需要以特定格式命名。 2 具体实现实现方式如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980@Slf4j@Componentpublic class ApplicationContextOperator implements ApplicationContextAware { private ApplicationContext applicationContext = null; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { log.info(&quot;application context 初始化&quot;); this.applicationContext = applicationContext; registerStrategyBean(); } private void registerStrategyBean() { log.info(&quot;开始注册策略 bean&quot;); List&lt;String&gt; allImplClassesByInterface = ClazzUtil.getAllImplClassesByInterface(FeatureInferStrategy.class); addStrategyBean(FeatureConstant.SPOT, allImplClassesByInterface); addStrategyBean(FeatureConstant.WRINKLE, allImplClassesByInterface); } private void addStrategyBean(String featureType, List&lt;String&gt; allImplClassesByInterface) { String featureName = TaskListUtil.getFeatureName(featureType); allImplClassesByInterface.stream().filter(e -&gt; e.toLowerCase().contains(featureName.toLowerCase())).findFirst().ifPresent(clazzName -&gt; { try { Class&lt;?&gt; subclass = Class.forName(clazzName); Constructor&lt;?&gt; constructor = subclass.getConstructor(String.class); FeatureInferStrategy strategyImpl = (FeatureInferStrategy) constructor.newInstance(featureName); String beanName = generateStrategyBeanName(strategyImpl.type()); registerSingletonBean(beanName, strategyImpl); } catch (ClassNotFoundException e) { e.printStackTrace(); log.info(&quot;no sub class, {}&quot;, clazzName); } catch (NoSuchMethodException e) { e.printStackTrace(); log.info(&quot;sub class {} no such method {}&quot;, clazzName, e.getMessage()); } catch (InvocationTargetException e) { e.printStackTrace(); } catch (InstantiationException | IllegalAccessException e) { log.info(&quot;msg: {}&quot;, e.getMessage()); e.printStackTrace(); } }); } /** * 生成策略类的 bean 名称 * * @param type * @return */ public static String generateStrategyBeanName(String type) { return type + &quot;Impl&quot;; } /** * 动态注入单例bean实例 * * @param beanName bean名称 * @param singletonObject 单例bean实例 * @return 注入实例 */ public Object registerSingletonBean(String beanName, Object singletonObject) { log.info(&quot;开始动态注入单例 bean, {}&quot;, beanName); //将applicationContext转换为ConfigurableApplicationContext ConfigurableApplicationContext configurableApplicationContext = (ConfigurableApplicationContext) this.applicationContext; //获取BeanFactory DefaultListableBeanFactory defaultListableBeanFactory = (DefaultListableBeanFactory) configurableApplicationContext.getAutowireCapableBeanFactory(); //动态注册bean. defaultListableBeanFactory.registerSingleton(beanName, singletonObject); //获取动态注册的bean. return configurableApplicationContext.getBean(beanName); }} 原理也很简单，通过 application context 的 spi，在注入 application context 的时候，进行 bean 的手动注册。 为什么要在这个时候注册呢？ 因为这个时候能够在程序启动较早的时候直接拿到 BeanFactory，如果要在启动程序较晚的时候再去拿，可能在跑测试用例的时候，并不能进行注册操作。 因为单元测试启动的时间，可能比你手动注册好 bean 之前还早。","link":"/2022/06/24/spring-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E5%85%A5-bean/"},{"title":"websocket session 分布式集群处理","text":"1 概述由于业务需要，导致开发的后端程序需要与前端通过 websocket 进行消息通信。于是采用了网上的一些做法，使用 spring websocket 集成 websocket 到 java 后端项目中。 但到了后来发现，这种将 websocket 端点与应用程序绑定在一起的方式有很大的问题。首先是业务服务的更新会导致跟客户端的连接断开，其次是比较难对 websocket 服务进行扩容。 于是想出了以下方案来针对上面两个主要问题来进行优化。 2 分布式 websocket session 具体实现之前通过网上资料，得到 websocket session 存储方式是将 session 存储到服务内存中。 2.1 websocket session 持久化基于上述方式实现，想到的第一个优化方式是参考 http session 一样，将 http session 序列化存储到 redis 中，以达到分布式的效果。 然而，等实现的时候才发现 websocket session 并不能序列化，这也就导致这种方案直接放弃。 2.2 websocket session 分布式 既然 websocket session 不能持久化，那是不是就意味着不能实现分布式呢？ 当然不会。持久化是一种实现方式，我们也可以不持久化。那不持久化又怎么实现分布式呢？ 我们可以参照注册中心和客户端服务的方式来处理。也就是说，我们可以将 redis 作为注册中心，websocket 服务自己去添加或删除自己服务中的 websocket session 信息，并将自身的 ip、端口等信息一起传输到 redis 特定键存储。 实现方式如图： 这样，当业务服务需要给某个用户的 websocket 客户端发信息时，只需要从 redis 的特定键中查找出用户属于哪个 websocket 服务，调用 websocket 服务的接口。websocket 服务收到业务服务的接口请求，则发送消息。","link":"/2022/06/24/websocket-session-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E5%A4%84%E7%90%86/"},{"title":"解决Python3pip安装速度慢问题","text":"1. 概述Python的pip源默认为国外源，下载速度慢。因此可以通过更换为国内源的方式进行解决。分为两种更换方式： 临时更换 全局更换 windows Linux 2. 临时更换 在使用pip的时候加参数 -i https://pypi.tuna.tsinghua.edu.cn/simple 如： 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pyspider 3. 全局更换3.1 windows环境 点击此电脑，在最上面的的文件夹窗口输入 ：%APPDATA%，回车 在该目录下新建一个pip目录，并在该文件夹下再新建一个pip.ini文件 在pip.ini文件中添加以下信息 1234[global]timeout = 6000index-url = https://pypi.tuna.tsinghua.edu.cn/simpletrusted-host = pypi.tuna.tsinghua.edu.cn 测试命令： 1pip install requests 3.2 linux环境与windows类似 Linux下，在home目录下创建一下.pip文件夹（命令：mkdir .pip） 在.pip文件夹下创建pip.conf文件（命令：touch pip.conf），文件内容如上。文件夹要加“.”，表示是隐藏文件夹) 至此，可以成功解决各种情况下pip安装Python库速度慢的问题。","link":"/2022/05/02/%E8%A7%A3%E5%86%B3Python3pip%E5%AE%89%E8%A3%85%E9%80%9F%E5%BA%A6%E6%85%A2%E9%97%AE%E9%A2%98/"},{"title":"常见接口优化思路","text":"1 概述大多数时候，等到功能实现完成，进行性能测试后会发现，接口速度响应速度不及预期。 一般的接口响应速度与用户体验对应关系如下： 接口响应耗时 用户体验 200 ms 及以下 瞬时发生 200 ms - 1s 用户可以感受到一些延迟，但却是可以接受的 1s 以上 用户就会有明显等待的感觉，等待时间越长，用户的使用体验就越差 比较好的系统的一个接口响应指标为： 99% 的接口请求响应速度要在 200 ms 以内， 99.99% 的请求要在 1s 以内 实际上，接口耗时有两个原因：io 与 cpu 计算。 io 很好理解，作为业务后端，必须有的数据库 io，还可能会有网络 io，文件 io。 cpu 计算主要是指通过编程语言进行算法运算的耗时，比如大数据的算法计算等。 大多数情况下，我们接口耗时较长都是因为 io。因为大概率，我们调用 cpu 计算，可能也就是算算 md5 之类的东西。 并且，对于 cpu 计算耗时的情况，也比较好处理，换用性能更好的算法就行了。 因此，在对接口优化之前，应该先分清接口所属的类型，是属于 CPU 型还是 io 型。 本文后面主要对 io 型的接口优化进行分析 2 优化方案在笔者之前遇到的项目中，大概可以以下几步去对接口进行优化： 使用并行进行处理 减少 io 次数 提升中间件性能 2.1 使用并行进行处理假设有这样一个场景，你需要根据多个 url 去进行网络请求下载图片。 每个网络请求都是会有耗时的，如果使用 for 循环或者普通的流操作去处理的话，最后下载这些图片的耗时，自然会是每个图片下载耗时累加的结果。 我们也很容易想到使用多线程来处理这个问题。在 Java8 之后，jdk 自身就提供了几种方式来让我们更加方便、透明的实现多线程处理数据。 parallel stream completable future 并行流是最简单、快速的一种实现方式，通过并行流可以很方便的实现并行，并且通过 lambda 表达式进行数据转换处理。 但同时它也有缺点。先想想我们之前想实现并行是怎么做的？ 我们之前要实现并行，并且为了充分利用资源，往往会使用一个线程池，并在池中定义多个线程，将任务提交到池中，让线程池去分配线程处理任务。 并行流虽然是帮我们 ”透明“的实现了并行，但实际底层实现也还是基于线程池操作线程来执行任务的。并行流底层对应了 jdk 自身内部定义的一个公共线程池（好像是叫 ForkJoinPool）。 因此，在极端情况下，假设这个公共线程池的线程因为任务执行耗时比较久，一直卡住，那么它将不能执行新的任务。笔者在以前线上环境中就曾经遇到过这样一个问题。 当然，这种情况比较极端，如果只是少量使用并行流的话，其实也不需要担心这个问题。 另外就是 completable future 了。 这是 jdk8 的新特性。completable future 相比 parallel stream，优势就在于能够自定义线程池，是专门用来批量处理同种任务的。 代码示例如下： 123456789101112131415161718192021222324252627282930313233343536373839404142ArrayList&lt;String&gt; urls = new ArrayList&lt;&gt;(4);for (int i = 0; i &lt; 100; i++) { urls.add(&quot;http://www.baidu.com&quot;);}int threads = (int) (Runtime.getRuntime().availableProcessors() * 0.8 * 100);System.out.println(&quot;threads = &quot; + threads);// 自定义线程数，充分利用资源Executor executorService = Executors.newFixedThreadPool(Math.min(urls.size(), threads), new ThreadFactory() { private AtomicInteger threadNum = new AtomicInteger(1); @Override public Thread newThread(Runnable r) { Thread thread = new Thread(r); thread.setDaemon(true); thread.setPriority(5); thread.setName(&quot;Thread Monitor &quot; + threadNum.incrementAndGet()); return thread; }});// 分为两个流操作进行调用，避免阻塞List&lt;CompletableFuture&lt;String&gt;&gt; collect = urls.stream().map(url -&gt; CompletableFuture.supplyAsync(() -&gt; { HttpResult httpResult = HTTP.builder().baseUrl(url).build().sync(&quot;&quot;).get(); int random = RandomUtil.randomInt(1, 10); try { int millis = random * 1000; String name = Thread.currentThread().getName(); System.out.println(&quot;Thread &quot; + name + &quot; millis = &quot; + millis); Thread.sleep(millis); } catch (InterruptedException e) { e.printStackTrace(); } return httpResult.getBody().toString();}, executorService)).collect(Collectors.toList());// 这样操作，耗时将会是最长的一个调用的时间Stopwatch s2 = Stopwatch.createStarted();List&lt;String&gt; results = collect.stream().map(CompletableFuture::join).collect(Collectors.toList());long d2 = s2.elapsed(TimeUnit.SECONDS);log.info(&quot;d2: {}&quot;, d2); 不过 completable future 相比 parallel stream，缺点就是在调用方式上比较麻烦。 2.2 减少 io 次数减少 io 次数，可以通过几种方式进行处理： 批量操作 预加载数据 优化逻辑 这里的批量处理是指使用一次批量处理代替多次循环。 比如，本来需要执行多条 sql 插入多条数据，但通过修改 sql，批量插入，那么只需要一条 sql 语句即可。 预加载数据是指，在数据量不多的情况下，可以先将一些基础的数据查询出来，然后使用在内存中进行计算。比如，教师和学生这两种数据，查询到内存中之后，可以将两者根据外键进行分组得到 map，这样结果前面的批处理，也能减少一些 io 次数。 优化逻辑则是通过修改逻辑，减少不必要的 io 次数，比如将数据库查询出的数据在方法中进行传递，那么在后续逻辑的方法中则不需要再进行 io。 2.3 提升中间件性能提升中间件性能有以下几种方式： 更换好的硬件 更改参数进行调优 使用更优的中间件 这个方式之所以要放到最后是因为，普遍来讲，这个工作在技术选型，中间件环境搭建的时候就会设置好一些东西。 因此，主要的接口调优思路还是会放在前两项上。","link":"/2022/06/24/%E5%B8%B8%E8%A7%81%E6%8E%A5%E5%8F%A3%E4%BC%98%E5%8C%96%E6%80%9D%E8%B7%AF/"},{"title":"Spring Cloud Gateway CORS 配置","text":"1 前言笔者在使用 spring cloud gateway 代理 springboot 项目的时候，发现：虽然springboot项目配置了 cors，但是前端通过 gateway 访问接口时仍然存在跨域问题。 通过排查，可以确认是 spring cloud gateway 没有配置跨域，因此，需要对其进行配置。 基于 spring cloud gateway 3.1.3 版本配置。 2 具体配置由于 springboot 项目端可以通过配置文件配置 allow-origin，因此 gateway 这边就直接放开所有。 配置如下： 12345678910111213141516171819202122232425262728293031323334spring: application: name: rage-gateway cloud: gateway: filter: remove-hop-by-hop: headers: # 以下是去掉网关默认去掉的请求响应头 - trailer - te - keep-alive - transfer-encoding - upgrade - proxy-authenticate - connection - proxy-authorization - x-application-context # 以下是去掉服务层面定义的跨域 - access-control-allow-credentials - access-control-allow-headers - access-control-allow-methods - access-control-allow-origin - access-control-max-age - vary globalcors: cors-configurations: '[/**]': allowCredentials: true allowedOriginPatterns: &quot;*&quot; allowedHeaders: &quot;*&quot; allowedMethods: &quot;*&quot; maxAge: 3628800 add-to-simple-url-handler-mapping: true 要注意的点如下： 要去除 header，不然列表中的 header 会出现两次 配置所有域名都可以访问的时候，如果allowCredentials为 true，则必须使用 allowedOriginPatterns，而不能使用 allowedOrigins add-to-simple-url-handler-mapping 为 true 时，代表对 cors 的预检请求直接放行，不需要计算","link":"/2022/08/01/Spring-Cloud-Gateway-CORS-%E9%85%8D%E7%BD%AE/"},{"title":"k8s 入门","text":"K8s 指南文章总结： 搭建一个基础的 k8s 集群，并以部署 nginx 为例，模拟服务进行部署，配置外网访问 1 创建 k8s 集群sealos 机器要求： 机器数：k8s-manager × 1，k8s-master × 3，k8s-node × 2 硬件：manager、master 统一 2c 4g，node 大于或等于 2c 4g k8s 版本：1.22.0 主机要求： hostname 每个机器必须不同 时区保持一致 关闭防火墙、selinux 操作系统均为 centos7 用户必须为 root，机器密码必须统一 查看节点信息： kubectl get nodes 2 创建工作负载资源2.1 创建 node创建 namespace： kubectl create namespace k8s-tutorial Pod 配置： 123456789101112131415161718192021222324252627282930apiVersion: v1kind: Podmetadata: name: &quot;nginx&quot; namespace: k8s-tutorial labels: app: &quot;nginx&quot;spec: containers: - name: nginx image: &quot;nginx:latest&quot; imagePullPolicy: IfNotPresent resources: limits: cpu: 200m memory: 500Mi requests: cpu: 100m memory: 200Mi ports: - containerPort: 80 name: http volumeMounts: - name: localtime mountPath: /etc/localtime volumes: - name: localtime hostPath: path: /usr/share/zoneinfo/Asia/Shanghai restartPolicy: Always 运行 pod： kubectl apply -f xxxx 查看 pod kubectl get pod -n k8s-tutorial -o wide 进入 pod 容器: kubectl exec -it nginx -n k8s-tutorial -- bash 访问 nginx node： curl -X GET http://100.113.22.195 查看 pod 详细信息与事件： kubectl describe pod nginx -n k8s-tutorial 2.2 pod 健康检查与恢复机制pod 健康检查方式： 命令式 http 方式 tcp grpc 方式 k8s 有多种探测器： 启动探测器 就绪探测器 存活探测器 如果一个 pod 被探测器检测为异常，那么 k8s 提供了几种方式对 pod 进行恢复 Always：只要 pod 不在运行状态，就重启容器 OnFailure：只在异常时才重启容器 Never：永远不重启容器 2.3 initContainer正常来讲，一个 pod 只运行一个容器。但有些时候，会需要运行多个容器。这种情况，统称为 sidecar 模式，比如 war 包与 web 服务，还有日志收集。 因此，需要一个 initContainer 来持有 pod 的 namespace 环境 2.4 创建 deployment注意：创建 deployment 时，pod 模板必须添加健康检测机制 因为如果不添加健康检测机制，deployment 将无法知道容器是否需要更新回滚 滚动更新（rolling-update）机制： deployment 控制 replicaset，replicaset 控制 pod 在默认机制下，deployment 每次更新，都是创建一个新的 replica set，新的 replica set 创建新的 pod（可以将 replica set 理解为 deployment 更新的版本）。这样，如果某次 deployment 更新失败，将可以通过回退 replica set 进行应用发布回退。但也可以通过设置，不创建新的 replica set deployment 蓝绿发布方式：https://github.com/ContainerSolutions/k8s-deployment-strategies.git 2.5 创建 serviceservice 有四种类型： nodeport loadbalancer clusterip external name 除了 cluster ip，其他都能外部访问 需要特殊说明的是，loadbalancer 类型的 service 需要集群本身带有负载均衡器。而自建的 k8s 集群默认是没有这个功能的，云厂商的 k8s 集群有这个功能。 因此，如果自建 k8s 集群想使用 loadbalancer 类型 service，得自己引入负载均衡器。 目前使用最广的是 metallb 2.5.1 metallb 安装官方文档：https://metallb.universe.tf/installation/ 分三步： 安装 metallb 配置 metallb 为二层模式 创建 loadbalancer 类型 service 2.5.2 创建 service123456789101112131415161718192021apiVersion: v1kind: Servicemetadata: name: nginx-service namespace: k8s-tutorialspec: selector: app: nginx type: LoadBalancer sessionAffinity: ClientIP sessionAffinityConfig: clientIP: timeoutSeconds: 10800 ports: - name: nginx-service protocol: TCP port: 80 targetPort: 80 # If you set the `spec.type` field to `NodePort` and you want a specific port number, # you can specify a value in the `spec.ports[*].nodePort` field. # nodePort: 80 sessionAffinity 可以理解为负载均衡规则，支持 none 和 clientIp。none 可以理解为随机访问，clientIp 可以理解为 ip hash 查看 service 信息： kubectl get service -n k8s-tutorial -o wide 此时，已经包含 external ip 信息 2.6 创建 ingress 下载 ingress-controller 配置文件 https://kubernetes.github.io/ingress-nginx/deploy/ 修改官方 ingress - controller 配置文件，添加 hostnetwork 配置 修改镜像源 https://hub.docker.com/u/anjia0532 ingress 配置： 1234567891011121314151617181920212223# https://kubernetes.io/docs/concepts/services-networking/ingress/#the-ingress-resourceapiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: nginx-ingress namespace: k8s-tutorial annotations: kubernetes.io/ingress.class: nginx nginx.ingress.kubernetes.io/rewrite-target: /spec: ingressClassName: nginx rules: - host: nginx.k8s.io http: paths: - path: / pathType: Prefix backend: service: name: nginx-service port: number: 80 检查安装结果： 检查安装结果： 访问： 客户端 client 添加 host 解析： 浏览器访问：","link":"/2022/07/18/k8s-%E5%85%A5%E9%97%A8/"},{"title":"keycloak 使用外部数据库","text":"","link":"/2022/07/14/keycloak-%E4%BD%BF%E7%94%A8%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"mysql 事务响应过慢","text":"","link":"/2022/07/19/mysql-%E4%BA%8B%E5%8A%A1%E5%93%8D%E5%BA%94%E8%BF%87%E6%85%A2/"},{"title":"keycloak 自定义 token 响应","text":"1 前言大多数时候，我们需要将用户额外的一些封装到 token 中进行返回。 比如这个用户，在它的 attribute 中具有一个 avatar 字段。如果我们只是使用 keycloak 标准的 token 的封装方式，里面根本不会有这个字段。 那么，怎么让 token 信息中包含这个字段呢？ 2 具体实现其实，使用 client 的 mapper 就能解决 具体操作流程如下： 找到对应 client，使用哪个 client 进行认证的，就选哪个。点击进入 找到 mapper，创建一个新的 mapper 此处我想将用户 attribute 中的 avatar 配置成 token 中的 avatar 字段，于是需要这样配置： Token claim name 就是 token 中字段的名称","link":"/2022/07/14/keycloak-%E8%87%AA%E5%AE%9A%E4%B9%89-token-%E5%93%8D%E5%BA%94/"},{"title":"mysql 并发新增数据问题","text":"","link":"/2022/07/19/mysql-%E5%B9%B6%E5%8F%91%E6%96%B0%E5%A2%9E%E6%95%B0%E6%8D%AE%E9%97%AE%E9%A2%98/"},{"title":"如何基于 keycloak spi 开发第三方社交账号登录","text":"","link":"/2022/07/14/%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8E-keycloak-spi-%E5%BC%80%E5%8F%91%E7%AC%AC%E4%B8%89%E6%96%B9%E7%A4%BE%E4%BA%A4%E8%B4%A6%E5%8F%B7%E7%99%BB%E5%BD%95/"},{"title":"基于 keycloak 的前后端分离架构","text":"","link":"/2022/07/14/%E5%9F%BA%E4%BA%8E-keycloak-%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E6%9E%B6%E6%9E%84/"},{"title":"keycloak https配置","text":"1 前言默认情况下，直接启动 keycloak，master realm 都是要求外部请求需要 https 方式访问的。 有两种方式可以解决： 使用 keycloak 自己生成的证书 自己生成证书或者阿里云证书 第一种方式，不需要自己生成证书，操作简单；但生成的证书用浏览器访问会被认为不安全，只能用于测试。 第二种方式，操作复杂一点；但生成的证书安全可靠。 下文会针对两种方式的实现都进行描述 环境要求： Docker Docker-compose 搭建之前，需要先安装 docker、docker-compose keycloak 版本：15.0.0 2 自动生成直接在 docker-compose 文件中，将宿主机的 443 端口映射到 keycloak 的 8443 端口即可。 123456789101112131415161718192021222324252627282930313233343536373839404142version: '2.1'services: keycloak: image: jboss/keycloak:15.0.0 container_name: keycloak ports: - 443:8443 environment: DB_VENDOR: mysql DB_DATABASE: keycloak DB_USER: keycloak DB_PASSWORD: keycloak KEYCLOAK_USER: admin KEYCLOAK_PASSWORD: admin JDBC_PARAMS: &quot;useSSL=false&quot; depends_on: mysql: condition: service_healthy networks: - keycloak-network mysql: image: mysql:5.7 container_name: mysql ports: - 3306:3306 healthcheck: test: [&quot;CMD&quot;, &quot;mysqladmin&quot; ,&quot;ping&quot;, &quot;-h&quot;, &quot;localhost&quot;] interval: 5s timeout: 3s retries: 10 environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: keycloak MYSQL_USER: keycloak MYSQL_PASSWORD: keycloak networks: - keycloak-networknetworks: keycloak-network: 3 手动生成 安装 certbot 1yum -y install certbot 生成证书 注意，这一步进行操作时，需要保证 80、443 端口打开且未被占用 1certbot certonly --standalone -d example.domain.cn -d example.domain.cn 使用证书 123cp /etc/letsencrypt/live/example.domain.cn/fullchain.pem ./certs/tls.crtcp /etc/letsencrypt/live/example.domain.cn/privkey.pem ./certs/tls.key 修改 docker-compose 文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445version: '2.1'services: keycloak: image: jboss/keycloak:15.0.0 container_name: keycloak ports: - 443:8443 volumes: - ./certs/tls.crt:/etc/x509/https/tls.crt - ./certs/tls.key:/etc/x509/https/tls.key environment: DB_VENDOR: mysql DB_DATABASE: keycloak DB_USER: keycloak DB_PASSWORD: keycloak KEYCLOAK_USER: admin KEYCLOAK_PASSWORD: admin JDBC_PARAMS: &quot;useSSL=false&quot; depends_on: mysql: condition: service_healthy networks: - keycloak-network mysql: image: mysql:5.7 container_name: mysql ports: - 3306:3306 healthcheck: test: [&quot;CMD&quot;, &quot;mysqladmin&quot; ,&quot;ping&quot;, &quot;-h&quot;, &quot;localhost&quot;] interval: 5s timeout: 3s retries: 10 environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: keycloak MYSQL_USER: keycloak MYSQL_PASSWORD: keycloak networks: - keycloak-networknetworks: keycloak-network: 其实这个方式的实现原理就是将证书文件，挂载容器内部即可。 但需要注意的是，证书文件名称必须为 tls.key、tls.crt 如果使用阿里云 nginx 证书的话，那么证书文件映射应该配置为： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647version: '2.1'services: keycloak: image: jboss/keycloak:15.0.0 container_name: keycloak ports: - 443:8443 volumes: - ./certs/xxx.pem:/etc/x509/https/tls.crt - ./certs/xxx.key:/etc/x509/https/tls.key environment: DB_VENDOR: mysql DB_DATABASE: keycloak DB_USER: keycloak DB_PASSWORD: keycloak KEYCLOAK_USER: admin KEYCLOAK_PASSWORD: admin JDBC_PARAMS: &quot;useSSL=false&quot; depends_on: mysql: condition: service_healthy networks: - keycloak-network mysql: image: mysql:5.7 container_name: mysql ports: - 3306:3306 healthcheck: test: [&quot;CMD&quot;, &quot;mysqladmin&quot; ,&quot;ping&quot;, &quot;-h&quot;, &quot;localhost&quot;] interval: 5s timeout: 3s retries: 10 environment: MYSQL_ROOT_PASSWORD: root MYSQL_DATABASE: keycloak MYSQL_USER: keycloak MYSQL_PASSWORD: keycloak networks: - keycloak-networknetworks: keycloak-network:","link":"/2022/07/14/keycloak-https%E9%85%8D%E7%BD%AE/"},{"title":"自动注册服务路由的实现","text":"","link":"/2022/08/04/%E8%87%AA%E5%8A%A8%E6%B3%A8%E5%86%8C%E6%9C%8D%E5%8A%A1%E8%B7%AF%E7%94%B1%E7%9A%84%E5%AE%9E%E7%8E%B0/"}],"tags":[{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"keycloak","slug":"keycloak","link":"/tags/keycloak/"},{"name":"jackson","slug":"jackson","link":"/tags/jackson/"},{"name":"rabbitmq","slug":"rabbitmq","link":"/tags/rabbitmq/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/tags/elasticsearch/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"spring data","slug":"spring-data","link":"/tags/spring-data/"},{"name":"websocket","slug":"websocket","link":"/tags/websocket/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"优化","slug":"优化","link":"/tags/%E4%BC%98%E5%8C%96/"},{"name":"spring cloud gateway","slug":"spring-cloud-gateway","link":"/tags/spring-cloud-gateway/"},{"name":"cors","slug":"cors","link":"/tags/cors/"},{"name":"spring cloud","slug":"spring-cloud","link":"/tags/spring-cloud/"},{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"token","slug":"token","link":"/tags/token/"},{"name":"前后端分离","slug":"前后端分离","link":"/tags/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB/"}],"categories":[{"name":"后端开发","slug":"后端开发","link":"/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"运维","slug":"运维","link":"/categories/%E8%BF%90%E7%BB%B4/"}]}